\chapter{Implementation Details} % Main chapter title

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Implementation of Elliptic Curve Operations}


Rust implementation of BLS12-381 from the pairing crate used by zCash was ported to OpenCL C. This step was straight-forward and made easier by the fixed size of primitive data types in both Rust and OpenCL C. Constants were used whereever it was possible, to aid compiler optimization. Almost all functions were inlined to remove the function call overhead, and open new opportunities for optimization. Due to the difficulty in debugging GPU and cryptographic code, almost every function is unit tested, and compared to the Rust implementation. No reduction in the number of variables was attempted like in THE PAPER ABOUT THE FAST MULTIEXPONENTIATION. Modern compiles rename every variable during compilation and perform multiple optimization passes.\
The host code is written in Rust to interface with the librustzcash Rust library, and uses ocl crate. Higher level interface is used for testing on Intel, NVIDIA and AMD GPUs. However, cross-compilation for Android some tests had to be implemented using the low-level API.\\
\\
Finite fields $\mathbb{F}_r$ (255-bit modulus) and $\mathbb{F}_q$ (381-bit modulus) have been ported to OpenCL, as well as an elliptic curve BLS12-381 group $\mathbb{G}_1$ over $\mathbb{F}_q$.

\section{Multiexponentiation Algorithms}

\subsection{Pippenger's Multiexponentiation Algorithm}
The most time-consuming part of proof generation is the multiplication of the elliptic curve points by the coefficients of the witness to create $\pi_A$, $\pi_B$ and $\pi_C$. In the multiplicative notation, this multiplication becomes exponentiation, so the algorithms solving this problem can also be called exponentiation algorithms.\\
\\
The actual problem we are trying to solve is:\\
\\
Given $x_1$, $x_2$,\dots, $x_n$ $\in \mathbb{G}$ and $y_1$, $y_2$,\dots, $y_n \in \mathbb{Z}$, compute $x_1^{y_1} x_2^{y_2} \dots x_n^{y_n}$.\\
\\
While square-and-multiply and windowed square-and-multiply are asymptotically optimal for a single exponentiation, it is possible to compute the multiexponentiation by grouping some terms, and exponentiating them together.\\
\\
\textbf{Example:} $2^3 5^3$ can be computed as $(2 \cdot 5)^3$.\\
\\
Pippinger's multiexponentiation algorithm can be used to calculate the required product. The algorithm can be used to calculate several multiproducts at once ($x_1^{y_1} x_2^{y_2} \dots x_n^{y_n}$, $x_1^{z_1} x_2^{z_2} \dots x_n^{z_n}$, $x_1^{p_1} x_2^{p_2} \dots x_n^{p_n}$ and Pippinger has proven that the algorithm is asymptotically optimal. However, for zk-SNARKs we require only one multiexponentiation, so the actual implementation is slightly simplified. For a good background on Pippinger's algorithm, as well as some alternatives (such as Yao's and Bos-Coster algorithm) please consult THE PAPER. In the rest of the section, we will discuss the simplified version of the Pippinger used in the bellman Rust crate.
\begin{algorithm}
\caption{Simplified Pippinger}\label{multiexp}
\begin{algorithmic}[1]
\Function{MultiexpInner}{\textit{Bases}[1 \dots n], \textit{Exponents}[1 \dots n], \textit{Shift}, \textit{Width}}

    \If{$Shift + Width < EXP\_BITS$}
        \State $Higher \gets \textbf{new thread}$ \Call{MultiexpInner}{\textit{Bases}, \textit{Exponents}, \textit{Shift}+\textit{Width}, \textit{Width}}
    \EndIf
    \State $Buckets \gets \textbf{new} \; Base[1\dots2^{Width}-1]$
    \State $Mask \gets 2^{Width}-1$
    \For{$i \gets 1 \dots n$}
        \State $ExpPart \gets (Exponents[i] \gg Shift) \; \&  \;Mask$
        \If{$ExpPart \neq 0$}
            \State $Buckets[ExpPart] \gets Buckets[ExpPart] + Bases[i]$
        \EndIf
    \EndFor
    
    \State $PartialSum \gets 0$
    \State $Sum \gets 0$
    
    \For{$i \gets 2^{Width}-1 \dots 1$}
        \State $PartialSum \gets PartialSum + Buckets[i]$
        \State $Sum \gets Sum + PartialSum$
    \EndFor
    
    \If{$Shift + Width < EXP\_BITS$}
        \State \textbf{wait} $Higher$
        \State $Sum \gets Sum + \cdot Higher^{2 \cdot Width}$ 
    \EndIf
    
    \State \textbf{return} $Sum$
\EndFunction
\\
\Function{Multiexp}{\textit{Bases}[1 \dots n], \textit{Exponents}[1 \dots n]}
    \If{n < 32}
        \State $Width \gets 3$
    \Else
        \State $Width \gets ln(n)$
    \EndIf

    \State \textbf{return} \Call{MultiexpInner}{$Bases$, $Exponents$, $0$, $Width$}
    
\EndFunction
\end{algorithmic}
\end{algorithm}

The algorithm segments the exponents in chunks of several bits. Every thread then iterates through the assigned bits, and based on them, adds bases to corresponding buckets. Buckets are then added in an efficient way:

$$ a + 2b + 3c = c + (c + b) + (c + b + a) $$

Afterwards, we wait for higher threads to finish, and combine results.\\
\\
As we can see this algorithm is quite paralellizable. We just need to change the width of the bit chunk to distribute work over more threads. Another possibility is to split the bases and exponents, and do the calculation separately. However, we notice some limitations as well. There is sequential work that needs to be done when we are combining results. We cannot split the work on more processors than there are bits in the exponent, without splitting the bases.
\\
\subsection{Implemented Algorithms}

% \subsubsection{Global Reduction}
% Global reduction kernel performs one step of reduction. It loads two elliptic curve points in projective coordinates, adds them, and writes them back to the memory. This kernel is called multiple times, with half the length every time, until we add all points together.
% \subsubsection{Local Reduction}
% Local reduction kernel tries to take advantage of faster local memory available on a GPU. It loads a group of points to local memory, and reduces them until only one point is left. Compared to the global reduction kernel, it uses more local memory, and as reduction progresses many computing units don't do any work. However, it needs to be called less times, and the number of loads from the global memory is significantly smaller.

\subsubsection{Square and Multiply}

\begin{algorithm}
    \caption{Square and Multiply}\label{sam}
    \begin{algorithmic}[1]
    \Function{SAM}{\textit{Base}, \textit{Exponent}}
    
        \State $Result \gets 1$
        \For{$i \gets Width \dots 1$}
            \State $Result \gets Result^2$
            \If{$Exponent[i] = 1$}
                \State $Result \gets Result \cdot Base$
            \EndIf
        \EndFor
        \State \textbf{return} $Result$
    \EndFunction
    \\
    \Function{Multiexp}{\textit{Bases}[1 \dots n], \textit{Exponents}[1 \dots n]}
        \State $Result \gets 1$
        \For{$i \gets 1 \dots n$}
            \State $Result \gets Result \cdot $\Call{SAM}{$Bases[i]$, $Exponents[i]$}
        \EndFor
    
        \State \textbf{return} $Result$
        
    \EndFunction
    \end{algorithmic}
\end{algorithm}
Square and multiply kernel implements the multiexponentiation in a simple way. Every elliptic curve point and exponent is loaded, exponentiated separately using the binary method, and written back to memory. Reduction algorithm is then called to produce the final result.
\subsubsection{Windowed Square and Multiply}
\begin{algorithm}
    \caption{Windowed Square and Multiply}\label{wsam}
    \begin{algorithmic}[1]
    \Function{WSAM}{\textit{Base}, \textit{Exponent}}
        \State $PowerTable[1 \dots Chunk] \gets \textbf{new} Base[1 \dots Chunk]$
        \State $CurrentPower \gets 1$
        \\
        \For{$i \gets 1 \dots Chunk$}
            \State $CurrentPower \gets CurrentPower \cdot Base$
            \State $PowerTable[i] \ gets CurrentPower$
        \EndFor
        \\
        \State $Result \gets 1$
        \For{$i \gets Width/Chunk \dots 1$}
            \State $Bits \gets $ \textit{Get }$i^{th}$ \textit{ Chunk From Exponent}
            \For{$j \gets 1 \dots Chunk$}
                \State $Result \gets Result^2$
            \EndFor
            \\
            \If{$Bits \neq 0$}
                \State $Result \gets Result \cdot PowerTable[Bits]$
            \EndIf
        \EndFor
        \\
        \State \textbf{return} $Result$
    \EndFunction
    \\
    \Function{Multiexp}{\textit{Bases}[1 \dots n], \textit{Exponents}[1 \dots n]}
        \State $Result \gets 1$
        \For{$i \gets 1 \dots n$}
            \State $Result \gets Result \cdot $\Call{WSAM}{$Bases[i]$, $Exponents[i]$}
        \EndFor
    
        \State \textbf{return} $Result$
        
    \EndFunction
    \end{algorithmic}
\end{algorithm}
Windowed method is similar to square-and-multiply. It also works with every point and exponent separately, but it processes the exponent 4 bits at a time. First, a lookup table is generated for the powers of the current base (powers 2-15). For every chunk of the exponent read, it performs the needed amount of doublings, and adds the corresponding power. This method uses more memory than ordinary square-and-multiply, but the number of operations is lower.
\subsubsection{Four-bit Pippenger's Algorithm}
This kernel is the closest to the Rust implementation of Pippenger's algorithm. Points are divided in chunks to take advantage of thousands processors on the GPU. Every thread then iterates through the points in the chunk, and reads the four-bit window in the exponent based on the thread index. Point is then added to the corresponding bucket. At the end, we add the buckets and write the result to shared local memory. Then we combine results from all threads working on the same chunk. This is done by a variation of a reduction algorithm working only on local memory. The chunk value is then written to global memory, and a reduction algorithm is called to combine all chunks together.
\subsubsection{Single-bit Pippenger's Algorithm}
In this implementation, points are divided in multiple chunks. Kernel threads are grouped in blocks of 256, and every thread is assigned to one bit position in the exponent. Every thread iterates through the points in its chunk, and adds all points where the tracked bit is one. When they are finished, threads write the results to the global memory. These sums are then reduced based on the bit in the exponent which was assigned to them. Finally, these 256 values are added together using the efficient addition algorithm from the previous section.
\subsubsection{Four-bit Pippenger's Algorithm with Separate Reduction}
We can notice that Windowed Pippenger's Algorithm kernel has an advantage that it performs less operations than Maximally Parllelized kernel. However, it features a local shared memory reduction step done on GPU, during which many processing units could be left without any work. This kernel starts as Four-bit Pippenger's algorithm, but writes the result of each thread to global memory, where they are reduced to 256 powers, and added to get the final result.
